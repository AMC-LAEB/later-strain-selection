{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identification Dominant circulating clade per season for US, Europe, and Australia and New Zealand\n",
    "\n",
    "**Assumptions:**\n",
    "- Northern hemisphere: \n",
    "  - flu season starts in October of year X and last through April of subsequent year X+1, the vaccine for this season is picked in February of year X\n",
    "  - 2011/2012 season is the cutoff from using HA1 sequence, using complete sequences afterwards\n",
    "- Southern hemisphere: \n",
    "  - flu season starts in March of year X and last through September of year X, the vaccine for this season in picked in September of the preceding year X-1\n",
    "  -  2011 season is the cutoff from using HA1 sequence, using complete sequences afterwards\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. General\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, dendropy, math\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from datetime import date, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2. General variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "passage_labels = ['clinical', 'cell-based MDCK or SIAT', 'cell-based other']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_hemispheres = {\"us\":\"nh\", \"europe\":\"nh\", \"aunz\":\"sh\"}\n",
    "hemispheres = [\"nh\", \"sh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_mature_protein = 17\n",
    "HA1_length_AA = 329 #in mature protein \n",
    "protein_length = 567\n",
    "sequence_length = 1701"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = 24 #preceding period in months\n",
    "pdur = 16 #period duration\n",
    "flu_seasons = {h:{} for h in hemispheres}\n",
    "vaccine_selection = {h:{} for h in hemispheres}\n",
    "for y in range(2002, 2024):\n",
    "    #northern hemisphere flu season\n",
    "    season = f\"{y}-{y+1}\"\n",
    "    if y != 2023:\n",
    "        flu_seasons[\"nh\"][season] = (date(y, 10, 1), date(y+1, 4, 30))\n",
    "        #northern hemisphere vaccine strain selection moment\n",
    "        vaccine_selection[\"nh\"][season] = date(y,2,1)\n",
    "    \n",
    "    if y==2002:\n",
    "        continue\n",
    "    #southern hemisphere flu season\n",
    "    flu_seasons[\"sh\"][str(y)] = (date(y, 3, 1), date(y, 9, 30))\n",
    "    #southern hemisphere vaccine strain selection moment\n",
    "    vaccine_selection[\"sh\"][str(y)] = date(y-1,9,1)\n",
    "\n",
    "season_periods = {h:{} for h in hemispheres}\n",
    "period_dates = {}\n",
    "for h, sd in flu_seasons.items():\n",
    "    for season, (fss, fse) in sd.items():\n",
    "        vsd = vaccine_selection[h][season]\n",
    "        #something with periods in treason doesn't seem to be correct but don't wanna waste time on that for now\n",
    "        if h == \"nh\":\n",
    "            ps, pe  = vsd + relativedelta(months=-pp), vsd + relativedelta(months=+pdur-1)\n",
    "        else:\n",
    "            ps, pe  = vsd + relativedelta(months=-pp), vsd + relativedelta(months=+pdur-1)\n",
    "\n",
    "        \n",
    "        period = f\"{str(ps.year)[2:]}{'0'+str(ps.month) if len(str(ps.month))==1 else str(ps.month)}-{str(pe.year)[2:]}{'0'+str(pe.month) if len(str(pe.month))==1 else str(pe.month)}\"\n",
    "        season_periods[h][season] = period\n",
    "        period_dates[period] = (ps, pe)\n",
    "\n",
    "#cut off for HA1 \n",
    "early_season_cutoff = {'nh':'2011-2012', 'sh':'2011'}\n",
    "early_season_cutoff_dates = {h:flu_seasons[h][season][-1] for h, season in early_season_cutoff.items()}\n",
    "early_seasons = [] #get list\n",
    "for h, cutoff in early_season_cutoff.items():\n",
    "    csons = list(flu_seasons[h].keys())\n",
    "    for i, season in enumerate(csons):\n",
    "        if i <= csons.index(cutoff):\n",
    "            early_seasons.append(season)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_leaf_nodes(node):\n",
    "    leafs = []\n",
    "    for child in node.postorder_iter():\n",
    "        if child.is_leaf():\n",
    "            leafs.append(child)\n",
    "    return leafs\n",
    "\n",
    "def get_mrca(nodes, tree):\n",
    "    for internal_node in tree.postorder_node_iter():\n",
    "        children = get_leaf_nodes(internal_node)\n",
    "        if all([node in children for node in nodes]):\n",
    "            return internal_node\n",
    "\n",
    "def get_consensus_sequence(sequences):\n",
    "    seqs = []\n",
    "    for seq in sequences:\n",
    "        if type(seq) == list:\n",
    "            seqs.append(seq)\n",
    "        else:\n",
    "            seqs.append(list(seq))\n",
    "    seqs = pd.DataFrame.from_records(seqs)#.reset_index(drop=)\n",
    "    consensus = seqs.mode().iloc[0,:].to_list()\n",
    "    return \"\".join(consensus)\n",
    "        \n",
    "def float_date_to_date(fd):\n",
    "    return date(math.floor(fd), 1, 1 ) + timedelta(days=(fd-math.floor(fd))*365)\n",
    "\n",
    "def get_dominant_clade(tree, phyclip, seqdict, fss, fse, n=1):\n",
    "    \n",
    "    #get sequences within flu season from   for phyclip data\n",
    "    clustecss_in_season = {}\n",
    "    for i, row in phyclip.iterrows():\n",
    "        if row[\"TAXA\"].split(\"|\")[0].replace(\" \", \"_\") in seqdict.keys():\n",
    "            try:\n",
    "                clustecss_in_season[row[\"CLUSTER\"]].append(row[\"TAXA\"].split(\"|\")[0].replace(\" \", \"_\") )\n",
    "            except:\n",
    "                clustecss_in_season[row[\"CLUSTER\"]] = [row[\"TAXA\"].split(\"|\")[0].replace(\" \", \"_\") ]\n",
    "    \n",
    "    cluster_seqs = {}\n",
    "    for cluster, leafs in clustecss_in_season.items():\n",
    "        \n",
    "        #get nodes of the phyclip cluster sequences in the big tree\n",
    "        nodes = []\n",
    "        for node in tree.leaf_node_iter():\n",
    "            if node.taxon.label.split(\"|\")[0].replace(\" \", \"_\") in leafs:\n",
    "                nodes.append(node)\n",
    "\n",
    "        #get most recent common ancestor of the cluster\n",
    "        mrca  = get_mrca(nodes, tree)\n",
    "        \n",
    "        #get sequences in seqs\n",
    "        if mrca.is_leaf():\n",
    "            try:\n",
    "                d = float_date_to_date(float(mrca.annotations.get_value(\"date\")))\n",
    "            except:\n",
    "                for k, v in mrca.annotations.values_as_dict().items():\n",
    "                    if k.split(\",\")[-1] == \"date\":\n",
    "                        d = float_date_to_date(float(v))\n",
    "            if d >= fss and d<=fse:\n",
    "                cluster_seqs[cluster] = [mrca.taxon.label.split(\"|\")[0].replace(\" \", \"_\")]\n",
    "        else:\n",
    "            leafs = get_leaf_nodes(mrca)\n",
    "            leafs_in_season = []\n",
    "            for node in leafs:\n",
    "                try:\n",
    "                    d = float_date_to_date(float(node.annotations.get_value(\"date\")))\n",
    "                except:\n",
    "                    for k, v in node.annotations.values_as_dict().items():\n",
    "                        if k.split(\",\")[-1] == \"date\":\n",
    "                            d = float_date_to_date(float(v))\n",
    "                if d >= fss and d<=fse:\n",
    "                    leafs_in_season.append(node.taxon.label.split(\"|\")[0].replace(\" \", \"_\"))\n",
    "            cluster_seqs[cluster] = leafs_in_season\n",
    "\n",
    "    clustecss_to_return = {}\n",
    "    while len(clustecss_to_return) < n and len(clustecss_to_return)<len(cluster_seqs):\n",
    "        #get biggest cluster \n",
    "        biggest_cluster = [k for k, l in cluster_seqs.items() if len(l) == max([len(l) for k,l  in cluster_seqs.items() if k not in list(clustecss_to_return.keys())]) and k not in list(clustecss_to_return.keys())][0]\n",
    "        seqs = [v for k,v in seqdict.items() if k in cluster_seqs[biggest_cluster]]\n",
    "        #get consensus\n",
    "        consensus = get_consensus_sequence(seqs)\n",
    "        clustecss_to_return[biggest_cluster] = consensus\n",
    "    if n > 1:\n",
    "        return clustecss_to_return\n",
    "    else:\n",
    "        return consensus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dominant strain per season per region\n",
    "\n",
    "Analysis is performed for influenza A/H3N2 HA sequences collected between 2000/01/01-2023/12/31   \n",
    "\n",
    "regions:\n",
    "- US\n",
    "- Europe\n",
    "- Australia and New Zealand\n",
    "  \n",
    "Dominant clade inferring using phyclip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Prep treason output trees for phyclip\n",
    "\n",
    "converting nexus to newich format and removing internal node names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tdir='../analysis/us_0023_feb_pp24_pd16/phyclip_input_trees'\n",
      "odir='../analysis/us_0023_feb_pp24_pd16/phyclip'\n",
      "\n",
      "tdir='../analysis/aunz_0023_sep_pp24_pd16/phyclip_input_trees'\n",
      "odir='../analysis/aunz_0023_sep_pp24_pd16/phyclip'\n",
      "\n",
      "tdir='../analysis/europe_0023_feb_pp24_pd16/phyclip_input_trees'\n",
      "odir='../analysis/europe_0023_feb_pp24_pd16/phyclip'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analysis_dir = \"../analysis\"\n",
    "for d in os.listdir(analysis_dir):\n",
    "    if os.path.isdir(os.path.join(analysis_dir,d)) and d.split(\"_\")[0] in list(region_hemispheres.keys()):\n",
    "        region = d.split(\"_\")[0]\n",
    "\n",
    "        phyclip_input_dir = os.path.join(analysis_dir, d, \"phyclip_input_trees\")\n",
    "        if not os.path.isdir(phyclip_input_dir):\n",
    "            os.mkdir(phyclip_input_dir)\n",
    "\n",
    "        treetime_dir = os.path.join(analysis_dir, d, \"treetime\")\n",
    "        if not os.path.isdir(treetime_dir):\n",
    "            print (f\"can not find treetime output for {region}\")\n",
    "\n",
    "        for f in os.listdir(os.path.join(treetime_dir)):\n",
    "            if f.endswith(\".nexus\") and \"divergence\" in f:\n",
    "                output_tree_file = os.path.join(os.path.join(phyclip_input_dir, f.replace(\"H3N2_HA\", f\"H3N2_HA_{region}\").replace(\".nexus\", \".tree\")))\n",
    "                if not os.path.isfile(output_tree_file):\n",
    "                    tree = dendropy.Tree.get(path=os.path.join(treetime_dir, f), schema=\"nexus\", preserve_underscores=True)\n",
    "                    tree.write(path=output_tree_file, schema=\"newick\", suppress_internal_node_labels=True,)\n",
    "                    print (output_tree_file) \n",
    "        \n",
    "        \n",
    "        print (f\"tdir='{phyclip_input_dir}'\\nodir='{os.path.join(analysis_dir, d, 'phyclip')}'\")\n",
    "        \n",
    "        print ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Run phylclip\n",
    "\n",
    "!! CHANGE ENVIRONMENTS: PHYCLIP REQUIRE PYTHON 2\n",
    "Manually specify path to tdir and odir as printed above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. gather phyclip output, sequences, metadata, and trees\n",
    "assuming phyclip output to be stored as printed above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get phyclip output\n",
    "phyclip_ex = \"phyclip\"\n",
    "\n",
    "phyclip_files = {region:{s:{} for s in season_periods[h].keys()}  for region, h in region_hemispheres.items()}\n",
    "for d in os.listdir(analysis_dir):\n",
    "    if os.path.isdir(os.path.join(analysis_dir,d)) and d.split(\"_\")[0] in list(region_hemispheres.keys()):\n",
    "        region = d.split(\"_\")[0]\n",
    "\n",
    "        phyclip_dir = os.path.join(analysis_dir, d, phyclip_ex)\n",
    "        if not os.path.isdir(phyclip_dir):\n",
    "            print (f\"can not find phyclip results for {region}\")\n",
    "\n",
    "        for f in os.listdir(phyclip_dir):\n",
    "            if f.startswith(\".\"):\n",
    "                continue #.DS store file #livelovemac\n",
    "            #determine season of interest from  file \n",
    "            p = f.split(\"_\")[-2]\n",
    "            if p not in season_periods[region_hemispheres[region]].values():\n",
    "                continue\n",
    "            \n",
    "            season = [s for s,pe in season_periods[region_hemispheres[region]].items() if pe ==p][0]\n",
    "\n",
    "            phyclip_files[region][season] = os.path.join(phyclip_dir, f)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get sequence output \n",
    "sequence_files = {region:{s:{} for s in season_periods[h].keys()}  for region, h in region_hemispheres.items()}\n",
    "for d in os.listdir(analysis_dir):\n",
    "    if os.path.isdir(os.path.join(analysis_dir,d)) and d.split(\"_\")[0] in list(region_hemispheres.keys()):\n",
    "        region = d.split(\"_\")[0]\n",
    "\n",
    "        #getting from alignment dir to sequences are trimmed to CDS\n",
    "        alignment_dir = os.path.join(analysis_dir,d, \"alignment\")\n",
    "        for f in os.listdir(alignment_dir):\n",
    "            if f.startswith(\".\"):\n",
    "                continue #.DS store file #livelovemac\n",
    "            #determine season of interest from  file \n",
    "            p = f.split(\"_\")[-2]\n",
    "            if p not in season_periods[region_hemispheres[region]].values():\n",
    "                continue\n",
    "            season = [s for s,pe in season_periods[region_hemispheres[region]].items() if pe ==p][0]\n",
    "            \n",
    "\n",
    "            sequence_files[region][season] = os.path.join(alignment_dir, f)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get metadata\n",
    "metadata_files = {region:{s:{} for s in season_periods[h].keys()}  for region, h in region_hemispheres.items()}\n",
    "for d in os.listdir(analysis_dir):\n",
    "    if os.path.isdir(os.path.join(analysis_dir,d)) and d.split(\"_\")[0] in list(region_hemispheres.keys()):\n",
    "        region = d.split(\"_\")[0]\n",
    "\n",
    "        #getting from alignment dir to sequences are trimmed to CDS\n",
    "        sequence_dir = os.path.join(analysis_dir,d, \"sequences\")\n",
    "        for f in os.listdir(sequence_dir):\n",
    "            if not  f.endswith(\".csv\"):\n",
    "                continue #.DS store file #livelovemac\n",
    "            #determine season of interest from  file \n",
    "            p = f.split(\"_\")[-2]\n",
    "            if p not in season_periods[region_hemispheres[region]].values():\n",
    "                continue\n",
    "            season = [s for s,pe in season_periods[region_hemispheres[region]].items() if pe ==p][0]\n",
    "            \n",
    "\n",
    "            metadata_files[region][season] = os.path.join(sequence_dir, f)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get tree files\n",
    "tree_files = {region:{p:{} for p in season_periods[h].values()}  for region, h in region_hemispheres.items()}\n",
    "for d in os.listdir(analysis_dir):\n",
    "    if os.path.isdir(os.path.join(analysis_dir,d)) and d.split(\"_\")[0] in list(region_hemispheres.keys()):\n",
    "        region = d.split(\"_\")[0]\n",
    "\n",
    "        #getting from alignment dir to sequences are trimmed to CDS\n",
    "        treetime_dir = os.path.join(analysis_dir,d, \"treetime\")\n",
    "        for f in os.listdir(treetime_dir):\n",
    "            if not f.endswith(\"timetree.nexus\") or \"dominant_clade\" in f:\n",
    "                continue #.DS store file #livelovemac\n",
    "            #determine season of interest from  file \n",
    "            p = f.split(\"_\")[-2]\n",
    "            if p not in season_periods[region_hemispheres[region]].values():\n",
    "                continue\n",
    "            season = [s for s,pe in season_periods[region_hemispheres[region]].items() if pe ==p][0]\n",
    "\n",
    "            tree_files[region][season] = os.path.join(treetime_dir, f)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Determine dominant strain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dominant_strain_file = '../data/dominant_strains.fasta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "redo = False\n",
    "if not os.path.isfile(dominant_strain_file) or redo:\n",
    "    dominant_strains = {}\n",
    "    for region, h in region_hemispheres.items():\n",
    "        for season, (fss, fse) in flu_seasons[h].items():\n",
    "\n",
    "            sequences = {r.id.split(\"|\")[0]:r.seq[:1701].replace(\"-\", \"N\").translate() for r in SeqIO.parse(sequence_files[region][season], \"fasta\")}\n",
    "            metadata = pd.read_csv(metadata_files[region][season])\n",
    "            metadata[\"Collection_Date\"] = [d.date() for d in pd.to_datetime(metadata[\"Collection_Date\"], errors='coerce')] \n",
    "            metadata = metadata[metadata[\"passage_category\"].isin(passage_labels)]\n",
    "\n",
    "            #get sequences within influenza season\n",
    "            seq_ids = metadata[(metadata[\"Collection_Date\"]>=fss)&(metadata[\"Collection_Date\"]<=fse)][\"Isolate_Id\"].to_list()\n",
    "            tree = dendropy.Tree.get(path=tree_files[region][season], schema=\"nexus\")\n",
    "            \n",
    "\n",
    "            phyclip = df = pd.read_csv(phyclip_files[region][season], sep=\"\\t\")\n",
    "            dominant_clade_consensus = get_dominant_clade(tree, phyclip, sequences, fss, fse)\n",
    "            if season in early_seasons and len(dominant_clade_consensus)>HA1_length_AA:\n",
    "                dominant_clade_consensus = dominant_clade_consensus[start_mature_protein-1:HA1_length_AA+start_mature_protein-1]\n",
    "                dominant_strains[f\"{region}_{season}_HA1\"] = dominant_clade_consensus\n",
    "            else:\n",
    "                dominant_strains[f\"{region}_{season}\"] = dominant_clade_consensus\n",
    "\n",
    "    with open(dominant_strain_file, \"w\") as fw:\n",
    "        for h, s in dominant_strains.items():\n",
    "            fw.write(f\">{h}\\n{s}\\n\") \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
