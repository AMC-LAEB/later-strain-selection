{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38ba2007",
   "metadata": {},
   "source": [
    "## Inspeciting sensitivitiy of phyclip, Robustness of dominant strain selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb6b526",
   "metadata": {},
   "source": [
    "## 0. General"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000bfcfd",
   "metadata": {},
   "source": [
    "### 0.1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af228678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, dendropy, math\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from datetime import date, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48ed822",
   "metadata": {},
   "source": [
    "### 0.2. General "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8654b8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "passage_labels = ['clinical', 'cell-based MDCK or SIAT', 'cell-based other']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fe91f240",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_hemispheres = {\"us\":\"nh\", \"europe\":\"nh\", \"aunz\":\"sh\"}\n",
    "hemispheres = [\"nh\", \"sh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fe4f81b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_mature_protein = 17\n",
    "HA1_length_AA = 329 #in mature protein \n",
    "protein_length = 567\n",
    "sequence_length = 1701"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4b1be125",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = 24 #preceding period in months\n",
    "pdur = 16 #period duration\n",
    "flu_seasons = {h:{} for h in hemispheres}\n",
    "vaccine_selection = {h:{} for h in hemispheres}\n",
    "for y in range(2002, 2024):\n",
    "    #northern hemisphere flu season\n",
    "    season = f\"{y}-{y+1}\"\n",
    "    if y != 2023:\n",
    "        flu_seasons[\"nh\"][season] = (date(y, 10, 1), date(y+1, 4, 30))\n",
    "        #northern hemisphere vaccine strain selection moment\n",
    "        vaccine_selection[\"nh\"][season] = date(y,2,1)\n",
    "    \n",
    "    if y==2002:\n",
    "        continue\n",
    "    #southern hemisphere flu season\n",
    "    flu_seasons[\"sh\"][str(y)] = (date(y, 3, 1), date(y, 9, 30))\n",
    "    #southern hemisphere vaccine strain selection moment\n",
    "    vaccine_selection[\"sh\"][str(y)] = date(y-1,9,1)\n",
    "\n",
    "season_periods = {h:{} for h in hemispheres}\n",
    "period_dates = {}\n",
    "for h, sd in flu_seasons.items():\n",
    "    for season, (fss, fse) in sd.items():\n",
    "        vsd = vaccine_selection[h][season]\n",
    "        #something with periods in treason doesn't seem to be correct but don't wanna waste time on that for now\n",
    "        if h == \"nh\":\n",
    "            ps, pe  = vsd + relativedelta(months=-pp), vsd + relativedelta(months=+pdur-1)\n",
    "        else:\n",
    "            ps, pe  = vsd + relativedelta(months=-pp), vsd + relativedelta(months=+pdur-1)\n",
    "\n",
    "        \n",
    "        period = f\"{str(ps.year)[2:]}{'0'+str(ps.month) if len(str(ps.month))==1 else str(ps.month)}-{str(pe.year)[2:]}{'0'+str(pe.month) if len(str(pe.month))==1 else str(pe.month)}\"\n",
    "        season_periods[h][season] = period\n",
    "        period_dates[period] = (ps, pe)\n",
    "\n",
    "#cut off for HA1 \n",
    "early_season_cutoff = {'nh':'2011-2012', 'sh':'2011'}\n",
    "early_season_cutoff_dates = {h:flu_seasons[h][season][-1] for h, season in early_season_cutoff.items()}\n",
    "early_seasons = [] #get list\n",
    "for h, cutoff in early_season_cutoff.items():\n",
    "    csons = list(flu_seasons[h].keys())\n",
    "    for i, season in enumerate(csons):\n",
    "        if i <= csons.index(cutoff):\n",
    "            early_seasons.append(season)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9e00cc",
   "metadata": {},
   "source": [
    "### 0.3. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "925f95ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_leaf_nodes(node):\n",
    "    leafs = []\n",
    "    for child in node.postorder_iter():\n",
    "        if child.is_leaf():\n",
    "            leafs.append(child)\n",
    "    return leafs\n",
    "\n",
    "def get_mrca(nodes, tree):\n",
    "    for internal_node in tree.postorder_node_iter():\n",
    "        children = get_leaf_nodes(internal_node)\n",
    "        if all([node in children for node in nodes]):\n",
    "            return internal_node\n",
    "\n",
    "def get_consensus_sequence(sequences):\n",
    "    seqs = []\n",
    "    for seq in sequences:\n",
    "        if type(seq) == list:\n",
    "            seqs.append(seq)\n",
    "        else:\n",
    "            seqs.append(list(seq))\n",
    "    seqs = pd.DataFrame.from_records(seqs)#.reset_index(drop=)\n",
    "    consensus = seqs.mode().iloc[0,:].to_list()\n",
    "    return \"\".join(consensus)\n",
    "        \n",
    "def float_date_to_date(fd):\n",
    "    return date(math.floor(fd), 1, 1 ) + timedelta(days=(fd-math.floor(fd))*365)\n",
    "\n",
    "def get_dominant_clade(tree, phyclip, seqdict, fss, fse, n=1):\n",
    "    \n",
    "    #get sequences within flu season from   for phyclip data\n",
    "    clustecss_in_season = {}\n",
    "    for i, row in phyclip.iterrows():\n",
    "        if row[\"TAXA\"].split(\"|\")[0].replace(\" \", \"_\") in seqdict.keys():\n",
    "            try:\n",
    "                clustecss_in_season[row[\"CLUSTER\"]].append(row[\"TAXA\"].split(\"|\")[0].replace(\" \", \"_\") )\n",
    "            except:\n",
    "                clustecss_in_season[row[\"CLUSTER\"]] = [row[\"TAXA\"].split(\"|\")[0].replace(\" \", \"_\") ]\n",
    "    \n",
    "    cluster_seqs = {}\n",
    "    for cluster, leafs in clustecss_in_season.items():\n",
    "        \n",
    "        #get nodes of the phyclip cluster sequences in the big tree\n",
    "        nodes = []\n",
    "        for node in tree.leaf_node_iter():\n",
    "            if node.taxon.label.split(\"|\")[0].replace(\" \", \"_\") in leafs:\n",
    "                nodes.append(node)\n",
    "\n",
    "        #get most recent common ancestor of the cluster\n",
    "        mrca  = get_mrca(nodes, tree)\n",
    "        \n",
    "        #get sequences in seqs\n",
    "        if mrca.is_leaf():\n",
    "            try:\n",
    "                d = float_date_to_date(float(mrca.annotations.get_value(\"date\")))\n",
    "            except:\n",
    "                for k, v in mrca.annotations.values_as_dict().items():\n",
    "                    if k.split(\",\")[-1] == \"date\":\n",
    "                        d = float_date_to_date(float(v))\n",
    "            if d >= fss and d<=fse:\n",
    "                cluster_seqs[cluster] = [mrca.taxon.label.split(\"|\")[0].replace(\" \", \"_\")]\n",
    "        else:\n",
    "            leafs = get_leaf_nodes(mrca)\n",
    "            leafs_in_season = []\n",
    "            for node in leafs:\n",
    "                try:\n",
    "                    d = float_date_to_date(float(node.annotations.get_value(\"date\")))\n",
    "                except:\n",
    "                    for k, v in node.annotations.values_as_dict().items():\n",
    "                        if k.split(\",\")[-1] == \"date\":\n",
    "                            d = float_date_to_date(float(v))\n",
    "                if d >= fss and d<=fse:\n",
    "                    leafs_in_season.append(node.taxon.label.split(\"|\")[0].replace(\" \", \"_\"))\n",
    "            cluster_seqs[cluster] = leafs_in_season\n",
    "\n",
    "    clustecss_to_return = {}\n",
    "    while len(clustecss_to_return) < n and len(clustecss_to_return)<len(cluster_seqs):\n",
    "        #get biggest cluster \n",
    "        biggest_cluster = [k for k, l in cluster_seqs.items() if len(l) == max([len(l) for k,l  in cluster_seqs.items() if k not in list(clustecss_to_return.keys())]) and k not in list(clustecss_to_return.keys())][0]\n",
    "        seqs = [v for k,v in seqdict.items() if k in cluster_seqs[biggest_cluster]]\n",
    "        #get consensus\n",
    "        consensus = get_consensus_sequence(seqs)\n",
    "        clustecss_to_return[biggest_cluster] = consensus\n",
    "    if n > 1:\n",
    "        return clustecss_to_return\n",
    "    else:\n",
    "        return consensus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1a0c5b",
   "metadata": {},
   "source": [
    "## 1. Prep phyclip run\n",
    "\n",
    "Should be performed already in dominant strain script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0ac22fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_dir = \"../analysis\"\n",
    "for d in os.listdir(analysis_dir):\n",
    "    if os.path.isdir(os.path.join(analysis_dir,d)) and d.split(\"_\")[0] in list(region_hemispheres.keys()):\n",
    "        region = d.split(\"_\")[0]\n",
    "\n",
    "        phyclip_input_dir = os.path.join(analysis_dir, d, \"phyclip_input_trees\")\n",
    "        if not os.path.isdir(phyclip_input_dir):\n",
    "            os.mkdir(phyclip_input_dir)\n",
    "\n",
    "        treetime_dir = os.path.join(analysis_dir, d, \"treetime\")\n",
    "        if not os.path.isdir(treetime_dir):\n",
    "            print (f\"can not find treetime output for {region}\")\n",
    "\n",
    "        for f in os.listdir(os.path.join(treetime_dir)):\n",
    "            if f.endswith(\".nexus\") and \"divergence\" in f:\n",
    "                output_tree_file = os.path.join(os.path.join(phyclip_input_dir, f.replace(\"H3N2_HA\", f\"H3N2_HA_{region}\").replace(\".nexus\", \".tree\")))\n",
    "                if not os.path.isfile(output_tree_file):\n",
    "                    tree = dendropy.Tree.get(path=os.path.join(treetime_dir, f), schema=\"nexus\", preserve_underscores=True)\n",
    "                    tree.write(path=output_tree_file, schema=\"newick\", suppress_internal_node_labels=True,)\n",
    "                    print (output_tree_file) \n",
    "        \n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816342a3",
   "metadata": {},
   "source": [
    "### 1.1. Run Phyclip\n",
    "\n",
    "running run_phyclip_sensitivity.py manually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27914859",
   "metadata": {},
   "source": [
    "## 2. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb21df8c",
   "metadata": {},
   "source": [
    "### 2.1. get output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f1b4ab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get phyclip output\n",
    "phyclip_output = \"../analysis/phyclip_sensitivity\"\n",
    "\n",
    "phyclip_files = {region:{s:{} for s in season_periods[h].keys()}  for region, h in region_hemispheres.items()}\n",
    "for f in os.listdir(phyclip_output):\n",
    "    if not f.startswith(\"cluster\"):\n",
    "        continue\n",
    "    \n",
    "    region = f.split(\"_\")[-3]\n",
    "    p = f.split(\"_\")[-2]\n",
    "    if p not in season_periods[region_hemispheres[region]].values():\n",
    "         continue\n",
    "            \n",
    "    season = [s for s,pe in season_periods[region_hemispheres[region]].items() if pe ==p][0]\n",
    "    \n",
    "    cs = int(f.split(\"_\")[3][2:])\n",
    "    fdr = float(f.split(\"_\")[4][3:])\n",
    "\n",
    "    phyclip_files[region][season][(cs, fdr)] = os.path.join(phyclip_output, f)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a76ef7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get sequence output \n",
    "sequence_files = {region:{s:{} for s in season_periods[h].keys()}  for region, h in region_hemispheres.items()}\n",
    "for d in os.listdir(analysis_dir):\n",
    "    if os.path.isdir(os.path.join(analysis_dir,d)) and d.split(\"_\")[0] in list(region_hemispheres.keys()):\n",
    "        region = d.split(\"_\")[0]\n",
    "\n",
    "        #getting from alignment dir to sequences are trimmed to CDS\n",
    "        alignment_dir = os.path.join(analysis_dir,d, \"alignment\")\n",
    "        for f in os.listdir(alignment_dir):\n",
    "            if f.startswith(\".\"):\n",
    "                continue #.DS store file #livelovemac\n",
    "            #determine season of interest from  file \n",
    "            p = f.split(\"_\")[-2]\n",
    "            if p not in season_periods[region_hemispheres[region]].values():\n",
    "                continue\n",
    "            season = [s for s,pe in season_periods[region_hemispheres[region]].items() if pe ==p][0]\n",
    "            \n",
    "\n",
    "            sequence_files[region][season] = os.path.join(alignment_dir, f)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0bac797d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get metadata\n",
    "metadata_files = {region:{s:{} for s in season_periods[h].keys()}  for region, h in region_hemispheres.items()}\n",
    "for d in os.listdir(analysis_dir):\n",
    "    if os.path.isdir(os.path.join(analysis_dir,d)) and d.split(\"_\")[0] in list(region_hemispheres.keys()):\n",
    "        region = d.split(\"_\")[0]\n",
    "\n",
    "        #getting from alignment dir to sequences are trimmed to CDS\n",
    "        sequence_dir = os.path.join(analysis_dir,d, \"sequences\")\n",
    "        for f in os.listdir(sequence_dir):\n",
    "            if not  f.endswith(\".csv\"):\n",
    "                continue #.DS store file #livelovemac\n",
    "            #determine season of interest from  file \n",
    "            p = f.split(\"_\")[-2]\n",
    "            if p not in season_periods[region_hemispheres[region]].values():\n",
    "                continue\n",
    "            season = [s for s,pe in season_periods[region_hemispheres[region]].items() if pe ==p][0]\n",
    "            \n",
    "\n",
    "            metadata_files[region][season] = os.path.join(sequence_dir, f)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "07a33049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get tree files\n",
    "tree_files = {region:{p:{} for p in season_periods[h].values()}  for region, h in region_hemispheres.items()}\n",
    "for d in os.listdir(analysis_dir):\n",
    "    if os.path.isdir(os.path.join(analysis_dir,d)) and d.split(\"_\")[0] in list(region_hemispheres.keys()):\n",
    "        region = d.split(\"_\")[0]\n",
    "\n",
    "        #getting from alignment dir to sequences are trimmed to CDS\n",
    "        treetime_dir = os.path.join(analysis_dir,d, \"treetime\")\n",
    "        for f in os.listdir(treetime_dir):\n",
    "            if not f.endswith(\"timetree.nexus\") or \"dominant_clade\" in f:\n",
    "                continue #.DS store file #livelovemac\n",
    "            #determine season of interest from  file \n",
    "            p = f.split(\"_\")[-2]\n",
    "            if p not in season_periods[region_hemispheres[region]].values():\n",
    "                continue\n",
    "            season = [s for s,pe in season_periods[region_hemispheres[region]].items() if pe ==p][0]\n",
    "\n",
    "            tree_files[region][season] = os.path.join(treetime_dir, f)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "612a35ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get og dominant strains\n",
    "dominant_strain_file = '../data/dominant_strains.fasta'\n",
    "\n",
    "dominant_strains = {region:{p:{} for p in flu_seasons[h].keys()}  for region, h in region_hemispheres.items()}\n",
    "for r in SeqIO.parse(dominant_strain_file, \"fasta\"):\n",
    "    region, season = r.id.split(\"_\")[0:2]\n",
    "    dominant_strains[region][season] = r.seq\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a90b98c",
   "metadata": {},
   "source": [
    "## 2.2. Determine dominant strains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "823cad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dominant_strain_file = '../data/sensitivity_analysis_dominant_strains.fasta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3f934f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "redo = False\n",
    "if not os.path.isfile(dominant_strain_file) or redo:\n",
    "    sensitivity_results = {region:{p:{} for p in flu_seasons[h].keys()}  for region, h in region_hemispheres.items()}\n",
    "    for region, sd in phyclip_files.items():\n",
    "        for season, phyclipd in sd.items():\n",
    "            \n",
    "            for (cs, fdr), f in phyclipd.items():\n",
    "                \n",
    "                #determine dominant strain first \n",
    "                sequences = {r.id.split(\"|\")[0]:r.seq[:1701].replace(\"-\", \"N\").translate() for r in SeqIO.parse(sequence_files[region][season], \"fasta\")}\n",
    "                metadata = pd.read_csv(metadata_files[region][season])\n",
    "                metadata[\"Collection_Date\"] = [d.date() for d in pd.to_datetime(metadata[\"Collection_Date\"], errors='coerce')] \n",
    "                metadata = metadata[metadata[\"passage_category\"].isin(passage_labels)]\n",
    "\n",
    "                #get sequences within influenza season\n",
    "                seq_ids = metadata[(metadata[\"Collection_Date\"]>=fss)&(metadata[\"Collection_Date\"]<=fse)][\"Isolate_Id\"].to_list()\n",
    "                tree = dendropy.Tree.get(path=tree_files[region][season], schema=\"nexus\")\n",
    "                \n",
    "\n",
    "                phyclip = pd.read_csv(f, sep=\"\\t\")\n",
    "                fss, fse = flu_seasons[region_hemispheres[region]][season]\n",
    "                dominant_clade_consensus = get_dominant_clade(tree, phyclip, sequences, fss, fse)\n",
    "                if season in early_seasons and len(dominant_clade_consensus)>HA1_length_AA:\n",
    "                    dominant_clade_consensus = dominant_clade_consensus[start_mature_protein-1:HA1_length_AA+start_mature_protein-1]\n",
    "                    \n",
    "                sensitivity_results[region][season][(cs, fdr)] = dominant_clade_consensus\n",
    "        \n",
    "    with open(dominant_strain_file, \"w\") as fw:\n",
    "        for region, sd in sensitivity_results.items():\n",
    "            for season, dsd in sd.items():\n",
    "                for (cs, fdr), strain in dsd.items():\n",
    "                    if season in early_seasons:\n",
    "                        fw.write(f\">{region}_{season}_cs{cs}_fdr{fdr}_HA1\\n{strain}\\n\") \n",
    "                    else:\n",
    "                        fw.write(f\">{region}_{season}_cs{cs}_fdr{fdr}\\n{strain}\\n\") \n",
    "                                \n",
    "else:\n",
    "    sensitivity_results_ = {region:{p:{} for p in flu_seasons[h].keys()}  for region, h in region_hemispheres.items()}\n",
    "    for r in SeqIO.parse(dominant_strain_file, \"fasta\"):\n",
    "        region, season = r.id.split(\"_\")[0:2]\n",
    "        cs = int(r.id.split(\"_\")[2][2:])\n",
    "        fdr = float(r.id.split(\"_\")[3][3:])\n",
    "        \n",
    "        sensitivity_results_[region][season][(cs, fdr)] = r.seq\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0eba86e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_results_overview = []\n",
    "for region, sd in sensitivity_results.items():\n",
    "    for season, dsd in sd.items():\n",
    "        dominant_strain = dominant_strains[region][season]\n",
    "        for (cs, fdr), strain in dsd.items():\n",
    "            \n",
    "            if strain == dominant_strain:\n",
    "                sensitivity_results_overview.append([region, season, cs, fdr, \"match\"])\n",
    "            else:\n",
    "                print (f\"no match for {region} {season} cs{cs} fdr{fdr}, write code to summarize differences\")\n",
    "\n",
    "sensitivity_results_overview = pd.DataFrame.from_records(sensitivity_results_overview, columns=[\"region\", \"season\", \"minimum cluster size\", \"fdr\", \"difference between identified dominant strain and original dominant strain (cs3, fdr0.2)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1d1a3d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_results_overview.to_csv(\"../data/sensitivity_analysis_dominant_strains_summary.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
