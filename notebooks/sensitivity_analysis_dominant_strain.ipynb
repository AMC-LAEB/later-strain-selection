{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38ba2007",
   "metadata": {},
   "source": [
    "## Inspeciting sensitivitiy of phyclip, Robustness of dominant strain selection\n",
    "\n",
    "parameters tested: \n",
    "- minimum cluster size: 3,5 \n",
    "- FDR: 0, 1\n",
    "\n",
    "Keep in mind minumum cluster size must be at least n tips / 2 > and minimum cluster size = 5 was therefore unsuccessfull in europe 2002-2003 season"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb6b526",
   "metadata": {},
   "source": [
    "## 0. General"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000bfcfd",
   "metadata": {},
   "source": [
    "### 0.1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af228678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, dendropy, math\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from datetime import date, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48ed822",
   "metadata": {},
   "source": [
    "### 0.2. General "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8654b8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "passage_labels = ['clinical', 'cell-based MDCK or SIAT', 'cell-based other']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe91f240",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_hemispheres = {\"us\":\"nh\", \"europe\":\"nh\", \"aunz\":\"sh\"}\n",
    "hemispheres = [\"nh\", \"sh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe4f81b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_mature_protein = 17\n",
    "HA1_length_AA = 329 #in mature protein \n",
    "protein_length = 567\n",
    "sequence_length = 1701"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b1be125",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = 24 #preceding period in months\n",
    "pdur = 16 #period duration\n",
    "flu_seasons = {h:{} for h in hemispheres}\n",
    "vaccine_selection = {h:{} for h in hemispheres}\n",
    "for y in range(2002, 2024):\n",
    "    #northern hemisphere flu season\n",
    "    season = f\"{y}-{y+1}\"\n",
    "    if y != 2023:\n",
    "        flu_seasons[\"nh\"][season] = (date(y, 10, 1), date(y+1, 4, 30))\n",
    "        #northern hemisphere vaccine strain selection moment\n",
    "        vaccine_selection[\"nh\"][season] = date(y,2,1)\n",
    "    \n",
    "    if y==2002:\n",
    "        continue\n",
    "    #southern hemisphere flu season\n",
    "    flu_seasons[\"sh\"][str(y)] = (date(y, 3, 1), date(y, 9, 30))\n",
    "    #southern hemisphere vaccine strain selection moment\n",
    "    vaccine_selection[\"sh\"][str(y)] = date(y-1,9,1)\n",
    "\n",
    "season_periods = {h:{} for h in hemispheres}\n",
    "period_dates = {}\n",
    "for h, sd in flu_seasons.items():\n",
    "    for season, (fss, fse) in sd.items():\n",
    "        vsd = vaccine_selection[h][season]\n",
    "        #something with periods in treason doesn't seem to be correct but don't wanna waste time on that for now\n",
    "        if h == \"nh\":\n",
    "            ps, pe  = vsd + relativedelta(months=-pp), vsd + relativedelta(months=+pdur-1)\n",
    "        else:\n",
    "            ps, pe  = vsd + relativedelta(months=-pp), vsd + relativedelta(months=+pdur-1)\n",
    "\n",
    "        \n",
    "        period = f\"{str(ps.year)[2:]}{'0'+str(ps.month) if len(str(ps.month))==1 else str(ps.month)}-{str(pe.year)[2:]}{'0'+str(pe.month) if len(str(pe.month))==1 else str(pe.month)}\"\n",
    "        season_periods[h][season] = period\n",
    "        period_dates[period] = (ps, pe)\n",
    "\n",
    "#cut off for HA1 \n",
    "early_season_cutoff = {'nh':'2011-2012', 'sh':'2011'}\n",
    "early_season_cutoff_dates = {h:flu_seasons[h][season][-1] for h, season in early_season_cutoff.items()}\n",
    "early_seasons = [] #get list\n",
    "for h, cutoff in early_season_cutoff.items():\n",
    "    csons = list(flu_seasons[h].keys())\n",
    "    for i, season in enumerate(csons):\n",
    "        if i <= csons.index(cutoff):\n",
    "            early_seasons.append(season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5bce914",
   "metadata": {},
   "outputs": [],
   "source": [
    "epitope_sites= {\"A\":[122,124,126,130,131,132,133,135,137,138,140,142,143,144,145,146,150,152,168], \n",
    "                \"B\":[128,129,155,156,157,158,159,163,165,186,187,188,189,190,192,193,194,196,197,198], \n",
    "                \"C\":[44,45,46,47,48,50,51,53,54,273,275,276,278,279,280,294,297,299,300,304,305,307,308,309,310,311,312], \n",
    "                \"D\":[96,102,103,117,121,167,170,171,172,173,174,175,176,177,179,182,201,203,207,208,209,212,213,214,215,216,217,218,219,226,227,228,229,230,238,240,242,244,246,247,248,], \n",
    "                \"E\":[57,59,62,63,67,75,78,80,81,82,83,86,87,88,91,92,94,109,260,261,262,265]}\n",
    "epitope_positions = [s for sites in epitope_sites.values() for s in sites]\n",
    "\n",
    "#rbs\n",
    "# rbs_positions = [98, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 144, 145, 146, 153, 154, 155, 156, 157, 158, 159,\n",
    "#                  183, 184, 185, 186, 187, 188, 189, 190, 190, 191, 192, 193, 194, 195, 196, 219, 220, 221, 222, 223, 224, \n",
    "#                  225, 226, 227, 228,]\n",
    "rbs_positions = [131, 132, 133, 134, 135, 136, 137, 138, 140, 183, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228,]\n",
    "koel_sites = [145, 189, 193, 156, 159, 158, 155]\n",
    "\n",
    "#amino acid list for coding \n",
    "aa_list = [\"A\", \"R\", \"N\", \"D\", \"C\", \"Q\", \"E\", \"G\", \"H\", \"I\", \"L\", \"K\", \"M\", \"F\", \"P\", \"S\", \"T\", \"W\", \"Y\", \"V\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9e00cc",
   "metadata": {},
   "source": [
    "### 0.3. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "925f95ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_leaf_nodes(node):\n",
    "    leafs = []\n",
    "    for child in node.postorder_iter():\n",
    "        if child.is_leaf():\n",
    "            leafs.append(child)\n",
    "    return leafs\n",
    "\n",
    "def get_mrca(nodes, tree):\n",
    "    for internal_node in tree.postorder_node_iter():\n",
    "        children = get_leaf_nodes(internal_node)\n",
    "        if all([node in children for node in nodes]):\n",
    "            return internal_node\n",
    "\n",
    "def get_consensus_sequence(sequences):\n",
    "    seqs = []\n",
    "    for seq in sequences:\n",
    "        if type(seq) == list:\n",
    "            seqs.append(seq)\n",
    "        else:\n",
    "            seqs.append(list(seq))\n",
    "    seqs = pd.DataFrame.from_records(seqs)#.reset_index(drop=)\n",
    "    consensus = seqs.mode().iloc[0,:].to_list()\n",
    "    return \"\".join(consensus)\n",
    "        \n",
    "def float_date_to_date(fd):\n",
    "    return date(math.floor(fd), 1, 1 ) + timedelta(days=(fd-math.floor(fd))*365)\n",
    "\n",
    "def get_dominant_clade(tree, phyclip, seqdict, fss, fse, n=1):\n",
    "    \n",
    "    #get sequences within flu season from   for phyclip data\n",
    "    clustecss_in_season = {}\n",
    "    for i, row in phyclip.iterrows():\n",
    "        if row[\"TAXA\"].split(\"|\")[0].replace(\" \", \"_\") in seqdict.keys():\n",
    "            try:\n",
    "                clustecss_in_season[row[\"CLUSTER\"]].append(row[\"TAXA\"].split(\"|\")[0].replace(\" \", \"_\") )\n",
    "            except:\n",
    "                clustecss_in_season[row[\"CLUSTER\"]] = [row[\"TAXA\"].split(\"|\")[0].replace(\" \", \"_\") ]\n",
    "    \n",
    "    cluster_seqs = {}\n",
    "    for cluster, leafs in clustecss_in_season.items():\n",
    "        \n",
    "        #get nodes of the phyclip cluster sequences in the big tree\n",
    "        nodes = []\n",
    "        for node in tree.leaf_node_iter():\n",
    "            if node.taxon.label.split(\"|\")[0].replace(\" \", \"_\") in leafs:\n",
    "                nodes.append(node)\n",
    "\n",
    "        #get most recent common ancestor of the cluster\n",
    "        mrca  = get_mrca(nodes, tree)\n",
    "        \n",
    "        #get sequences in seqs\n",
    "        if mrca.is_leaf():\n",
    "            try:\n",
    "                d = float_date_to_date(float(mrca.annotations.get_value(\"date\")))\n",
    "            except:\n",
    "                for k, v in mrca.annotations.values_as_dict().items():\n",
    "                    if k.split(\",\")[-1] == \"date\":\n",
    "                        d = float_date_to_date(float(v))\n",
    "            if d >= fss and d<=fse:\n",
    "                cluster_seqs[cluster] = [mrca.taxon.label.split(\"|\")[0].replace(\" \", \"_\")]\n",
    "        else:\n",
    "            leafs = get_leaf_nodes(mrca)\n",
    "            leafs_in_season = []\n",
    "            for node in leafs:\n",
    "                try:\n",
    "                    d = float_date_to_date(float(node.annotations.get_value(\"date\")))\n",
    "                except:\n",
    "                    for k, v in node.annotations.values_as_dict().items():\n",
    "                        if k.split(\",\")[-1] == \"date\":\n",
    "                            d = float_date_to_date(float(v))\n",
    "                if d >= fss and d<=fse:\n",
    "                    leafs_in_season.append(node.taxon.label.split(\"|\")[0].replace(\" \", \"_\"))\n",
    "            cluster_seqs[cluster] = leafs_in_season\n",
    "\n",
    "    clustecss_to_return = {}\n",
    "    while len(clustecss_to_return) < n and len(clustecss_to_return)<len(cluster_seqs):\n",
    "        #get biggest cluster \n",
    "        biggest_cluster = [k for k, l in cluster_seqs.items() if len(l) == max([len(l) for k,l  in cluster_seqs.items() if k not in list(clustecss_to_return.keys())]) and k not in list(clustecss_to_return.keys())][0]\n",
    "        seqs = [v for k,v in seqdict.items() if k in cluster_seqs[biggest_cluster]]\n",
    "        #get consensus\n",
    "        consensus = get_consensus_sequence(seqs)\n",
    "        clustecss_to_return[biggest_cluster] = consensus\n",
    "    if n > 1:\n",
    "        return clustecss_to_return\n",
    "    else:\n",
    "        return consensus\n",
    "    \n",
    "def find_mismatch_HA(s1, s2):\n",
    "    \n",
    "    signal_peptide=  []\n",
    "    epitope = []\n",
    "    non_epitope = []\n",
    "\n",
    "    \n",
    "    if len(s1) != len(s2):\n",
    "        print (\"unequal length\")\n",
    "    if len(s1) > 329:\n",
    "        \n",
    "        #starting with signal peptide\n",
    "        signal_peptide=  []\n",
    "        for i, aa in enumerate(s1[:start_mature_protein-1]):\n",
    "            if aa != s2[i]:\n",
    "                signal_peptide.append(f\"{aa}{i+1}{s2[i]}\")\n",
    "            \n",
    "         #mature protein\n",
    "        for i, aa in enumerate(s1[start_mature_protein-1:]):\n",
    "            if s2[start_mature_protein-1:][i]!=aa:\n",
    "                if i in epitope_positions:\n",
    "                    epitope.append(f\"{aa}{i+1}{s2[i]}\")\n",
    "                else:\n",
    "                    non_epitope.append(f\"{aa}{i+1}{s2[i]}\")\n",
    "    else:\n",
    "        #just HA1\n",
    "        for i, aa in enumerate(s1[:start_mature_protein-1]):\n",
    "            if aa != s2[i]:\n",
    "                if i in epitope_positions:\n",
    "                    epitope.append(f\"{aa}{i+1}{s2[i]}\")\n",
    "                else:\n",
    "                    non_epitope.append(f\"{aa}{i+1}{s2[i]}\")\n",
    "       \n",
    "    sum = []             \n",
    "    if len(signal_peptide) > 0:\n",
    "        sum.append(\"sig pep: \"+\", \".join(signal_peptide))\n",
    "    if len(epitope) >0:\n",
    "        sum.append(\"epitope: \"+\", \".join(epitope))\n",
    "    if len(non_epitope) > 0:\n",
    "        sum.append(\"non-epitope: \"+\", \".join(non_epitope))\n",
    "        \n",
    "    return \"; \".join(sum)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1a0c5b",
   "metadata": {},
   "source": [
    "## 1. Prep phyclip run\n",
    "\n",
    "Should be performed already in dominant strain script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ac22fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_dir = \"../analysis\"\n",
    "for d in os.listdir(analysis_dir):\n",
    "    if os.path.isdir(os.path.join(analysis_dir,d)) and d.split(\"_\")[0] in list(region_hemispheres.keys()):\n",
    "        region = d.split(\"_\")[0]\n",
    "\n",
    "        phyclip_input_dir = os.path.join(analysis_dir, d, \"phyclip_input_trees\")\n",
    "        if not os.path.isdir(phyclip_input_dir):\n",
    "            os.mkdir(phyclip_input_dir)\n",
    "\n",
    "        treetime_dir = os.path.join(analysis_dir, d, \"treetime\")\n",
    "        if not os.path.isdir(treetime_dir):\n",
    "            print (f\"can not find treetime output for {region}\")\n",
    "\n",
    "        for f in os.listdir(os.path.join(treetime_dir)):\n",
    "            if f.endswith(\".nexus\") and \"divergence\" in f:\n",
    "                output_tree_file = os.path.join(os.path.join(phyclip_input_dir, f.replace(\"H3N2_HA\", f\"H3N2_HA_{region}\").replace(\".nexus\", \".tree\")))\n",
    "                if not os.path.isfile(output_tree_file):\n",
    "                    tree = dendropy.Tree.get(path=os.path.join(treetime_dir, f), schema=\"nexus\", preserve_underscores=True)\n",
    "                    tree.write(path=output_tree_file, schema=\"newick\", suppress_internal_node_labels=True,)\n",
    "                    print (output_tree_file) \n",
    "        \n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816342a3",
   "metadata": {},
   "source": [
    "### 1.1. Run Phyclip\n",
    "\n",
    "running run_phyclip_sensitivity.py manually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27914859",
   "metadata": {},
   "source": [
    "## 2. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb21df8c",
   "metadata": {},
   "source": [
    "### 2.1. get output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1b4ab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get phyclip output\n",
    "phyclip_output = \"../analysis/phyclip_sensitivity\"\n",
    "\n",
    "phyclip_files = {region:{s:{} for s in season_periods[h].keys()}  for region, h in region_hemispheres.items()}\n",
    "for f in os.listdir(phyclip_output):\n",
    "    if not f.startswith(\"cluster\"):\n",
    "        continue\n",
    "    \n",
    "    region = f.split(\"_\")[-3]\n",
    "    p = f.split(\"_\")[-2]\n",
    "    if p not in season_periods[region_hemispheres[region]].values():\n",
    "         continue\n",
    "            \n",
    "    season = [s for s,pe in season_periods[region_hemispheres[region]].items() if pe ==p][0]\n",
    "    \n",
    "    cs = int(f.split(\"_\")[3][2:])\n",
    "    fdr = float(f.split(\"_\")[4][3:])\n",
    "\n",
    "    phyclip_files[region][season][(cs, fdr)] = os.path.join(phyclip_output, f)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a76ef7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get sequence output \n",
    "sequence_files = {region:{s:{} for s in season_periods[h].keys()}  for region, h in region_hemispheres.items()}\n",
    "for d in os.listdir(analysis_dir):\n",
    "    if os.path.isdir(os.path.join(analysis_dir,d)) and d.split(\"_\")[0] in list(region_hemispheres.keys()):\n",
    "        region = d.split(\"_\")[0]\n",
    "\n",
    "        #getting from alignment dir to sequences are trimmed to CDS\n",
    "        alignment_dir = os.path.join(analysis_dir,d, \"alignment\")\n",
    "        for f in os.listdir(alignment_dir):\n",
    "            if f.startswith(\".\"):\n",
    "                continue #.DS store file #livelovemac\n",
    "            #determine season of interest from  file \n",
    "            p = f.split(\"_\")[-2]\n",
    "            if p not in season_periods[region_hemispheres[region]].values():\n",
    "                continue\n",
    "            season = [s for s,pe in season_periods[region_hemispheres[region]].items() if pe ==p][0]\n",
    "            \n",
    "\n",
    "            sequence_files[region][season] = os.path.join(alignment_dir, f)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bac797d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get metadata\n",
    "metadata_files = {region:{s:{} for s in season_periods[h].keys()}  for region, h in region_hemispheres.items()}\n",
    "for d in os.listdir(analysis_dir):\n",
    "    if os.path.isdir(os.path.join(analysis_dir,d)) and d.split(\"_\")[0] in list(region_hemispheres.keys()):\n",
    "        region = d.split(\"_\")[0]\n",
    "\n",
    "        #getting from alignment dir to sequences are trimmed to CDS\n",
    "        sequence_dir = os.path.join(analysis_dir,d, \"sequences\")\n",
    "        for f in os.listdir(sequence_dir):\n",
    "            if not  f.endswith(\".csv\"):\n",
    "                continue #.DS store file #livelovemac\n",
    "            #determine season of interest from  file \n",
    "            p = f.split(\"_\")[-2]\n",
    "            if p not in season_periods[region_hemispheres[region]].values():\n",
    "                continue\n",
    "            season = [s for s,pe in season_periods[region_hemispheres[region]].items() if pe ==p][0]\n",
    "            \n",
    "\n",
    "            metadata_files[region][season] = os.path.join(sequence_dir, f)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07a33049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get tree files\n",
    "tree_files = {region:{p:{} for p in season_periods[h].values()}  for region, h in region_hemispheres.items()}\n",
    "for d in os.listdir(analysis_dir):\n",
    "    if os.path.isdir(os.path.join(analysis_dir,d)) and d.split(\"_\")[0] in list(region_hemispheres.keys()):\n",
    "        region = d.split(\"_\")[0]\n",
    "\n",
    "        #getting from alignment dir to sequences are trimmed to CDS\n",
    "        treetime_dir = os.path.join(analysis_dir,d, \"treetime\")\n",
    "        for f in os.listdir(treetime_dir):\n",
    "            if not f.endswith(\"timetree.nexus\") or \"dominant_clade\" in f:\n",
    "                continue #.DS store file #livelovemac\n",
    "            #determine season of interest from  file \n",
    "            p = f.split(\"_\")[-2]\n",
    "            if p not in season_periods[region_hemispheres[region]].values():\n",
    "                continue\n",
    "            season = [s for s,pe in season_periods[region_hemispheres[region]].items() if pe ==p][0]\n",
    "\n",
    "            tree_files[region][season] = os.path.join(treetime_dir, f)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "612a35ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get og dominant strains\n",
    "dominant_strain_file = '../data/dominant_strains.fasta'\n",
    "\n",
    "dominant_strains = {region:{p:{} for p in flu_seasons[h].keys()}  for region, h in region_hemispheres.items()}\n",
    "for r in SeqIO.parse(dominant_strain_file, \"fasta\"):\n",
    "    region, season = r.id.split(\"_\")[0:2]\n",
    "    dominant_strains[region][season] = r.seq\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a90b98c",
   "metadata": {},
   "source": [
    "### 2.2. Determine dominant strains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "823cad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dominant_strain_file = '../data/sensitivity_analysis_dominant_strains.fasta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f934f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "redo = False\n",
    "if not os.path.isfile(dominant_strain_file) or redo:\n",
    "    sensitivity_results = {region:{p:{} for p in flu_seasons[h].keys()}  for region, h in region_hemispheres.items()}\n",
    "    for region, sd in phyclip_files.items():\n",
    "        for season, phyclipd in sd.items():\n",
    "            \n",
    "            for (cs, fdr), f in phyclipd.items():\n",
    "                \n",
    "                #determine dominant strain first \n",
    "                sequences = {r.id.split(\"|\")[0]:r.seq[:1701].replace(\"-\", \"N\").translate() for r in SeqIO.parse(sequence_files[region][season], \"fasta\")}\n",
    "                metadata = pd.read_csv(metadata_files[region][season])\n",
    "                metadata[\"Collection_Date\"] = [d.date() for d in pd.to_datetime(metadata[\"Collection_Date\"], errors='coerce')] \n",
    "                metadata = metadata[metadata[\"passage_category\"].isin(passage_labels)]\n",
    "\n",
    "                #get sequences within influenza season\n",
    "                seq_ids = metadata[(metadata[\"Collection_Date\"]>=fss)&(metadata[\"Collection_Date\"]<=fse)][\"Isolate_Id\"].to_list()\n",
    "                tree = dendropy.Tree.get(path=tree_files[region][season], schema=\"nexus\")\n",
    "                \n",
    "\n",
    "                phyclip = pd.read_csv(f, sep=\"\\t\")\n",
    "                fss, fse = flu_seasons[region_hemispheres[region]][season]\n",
    "                dominant_clade_consensus = get_dominant_clade(tree, phyclip, sequences, fss, fse)\n",
    "                if season in early_seasons and len(dominant_clade_consensus)>HA1_length_AA:\n",
    "                    dominant_clade_consensus = dominant_clade_consensus[start_mature_protein-1:HA1_length_AA+start_mature_protein-1]\n",
    "                    \n",
    "                sensitivity_results[region][season][(cs, fdr)] = dominant_clade_consensus\n",
    "        \n",
    "    with open(dominant_strain_file, \"w\") as fw:\n",
    "        for region, sd in sensitivity_results.items():\n",
    "            for season, dsd in sd.items():\n",
    "                for (cs, fdr), strain in dsd.items():\n",
    "                    if season in early_seasons:\n",
    "                        fw.write(f\">{region}_{season}_cs{cs}_fdr{fdr}_HA1\\n{strain}\\n\") \n",
    "                    else:\n",
    "                        fw.write(f\">{region}_{season}_cs{cs}_fdr{fdr}\\n{strain}\\n\") \n",
    "                                \n",
    "else:\n",
    "    sensitivity_results = {region:{p:{} for p in flu_seasons[h].keys()}  for region, h in region_hemispheres.items()}\n",
    "    for r in SeqIO.parse(dominant_strain_file, \"fasta\"):\n",
    "        region, season = r.id.split(\"_\")[0:2]\n",
    "        cs = int(r.id.split(\"_\")[2][2:])\n",
    "        fdr = float(r.id.split(\"_\")[3][3:])\n",
    "        \n",
    "        sensitivity_results[region][season][(cs, fdr)] = r.seq\n",
    "    \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8782b736",
   "metadata": {},
   "source": [
    "### 2.3. compare dominant strain with the original dominant strain file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0eba86e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no match for europe 2022-2023 cs5 fdr0.1\n",
      "no match for europe 2022-2023 cs5 fdr0.2\n",
      "no match for aunz 2018 cs3 fdr0.1\n",
      "no match for aunz 2018 cs5 fdr0.2\n",
      "no match for aunz 2018 cs3 fdr0.2\n",
      "no match for aunz 2018 cs5 fdr0.1\n"
     ]
    }
   ],
   "source": [
    "#get an overview of the match\n",
    "sensitivity_results_overview = []\n",
    "for region, sd in sensitivity_results.items():\n",
    "    for season, dsd in sd.items():\n",
    "        dominant_strain = dominant_strains[region][season]\n",
    "        for (cs, fdr), strain in dsd.items():\n",
    "            \n",
    "            if strain == dominant_strain:\n",
    "                sensitivity_results_overview.append([region, season, cs, fdr, \"match\"])\n",
    "            else:\n",
    "                sensitivity_results_overview.append([region, season, cs, fdr, find_mismatch_HA(dominant_strain, strain)])\n",
    "                \n",
    "                print (f\"no match for {region} {season} cs{cs} fdr{fdr}\")\n",
    "\n",
    "sensitivity_results_overview = pd.DataFrame.from_records(sensitivity_results_overview, columns=[\"region\", \"season\", \"minimum cluster size\", \"fdr\", \"difference between identified dominant strain and original dominant strain (cs3, fdr0.2)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6287b1a5",
   "metadata": {},
   "source": [
    "### 2.4. investigation robustness of mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "340ef14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>minimum cluster size</th>\n",
       "      <th>fdr</th>\n",
       "      <th>difference between identified dominant strain and original dominant strain (cs3, fdr0.2)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <th>season</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">aunz</th>\n",
       "      <th>2018</th>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>epitope: N171T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>epitope: N171T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>epitope: N171T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>epitope: N171T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">europe</th>\n",
       "      <th>2022-2023</th>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>epitope: S262N; non-epitope: R33H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-2023</th>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>epitope: S262N; non-epitope: R33H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  minimum cluster size  fdr  \\\n",
       "region season                                 \n",
       "aunz   2018                          3  0.1   \n",
       "       2018                          5  0.2   \n",
       "       2018                          3  0.2   \n",
       "       2018                          5  0.1   \n",
       "europe 2022-2023                     5  0.1   \n",
       "       2022-2023                     5  0.2   \n",
       "\n",
       "                 difference between identified dominant strain and original dominant strain (cs3, fdr0.2)  \n",
       "region season                                                                                              \n",
       "aunz   2018                                          epitope: N171T                                        \n",
       "       2018                                          epitope: N171T                                        \n",
       "       2018                                          epitope: N171T                                        \n",
       "       2018                                          epitope: N171T                                        \n",
       "europe 2022-2023                  epitope: S262N; non-epitope: R33H                                        \n",
       "       2022-2023                  epitope: S262N; non-epitope: R33H                                        "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mismatch_df = sensitivity_results_overview[sensitivity_results_overview[\"difference between identified dominant strain and original dominant strain (cs3, fdr0.2)\"]!=\"match\"]\n",
    "mismatch_df = mismatch_df.set_index([\"region\", \"season\"]).sort_index()\n",
    "mismatch_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e268db93",
   "metadata": {},
   "source": [
    "visual inspection shows no Koel site mutations, so only loading epitope mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c851114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get original epitope mutation difference results \n",
    "#dominant strain vs WHO vacine strain (VS)\n",
    "ds_vs = pd.read_csv(\"../analysis/genetic_comparison_results/mutations_dominant_strain_vs_vaccine_strain.csv\")\n",
    "ds_vs[\"comparison\"] = \"DS vs VS\"\n",
    "\n",
    "#dominant strain vs reproducible selection strain at WHO timing (CSS)\n",
    "ds_css = pd.read_csv(\"../analysis/genetic_comparison_results/mutations_dominant_strain_vs_reproducible_selection_at_WHO-timing.csv\")\n",
    "ds_css[\"comparison\"] = \"DS vs CSS\"\n",
    "\n",
    "#dominant strain vs later selection strain (reproducible) (LSS)\n",
    "ds_lss = pd.read_csv(\"../analysis/genetic_comparison_results/mutations_dominant_strain_vs_reproducible_selection_at_delayed_timing.csv\")\n",
    "ds_lss[\"comparison\"] = \"DS vs LSS\"\n",
    "\n",
    "genetic_comparison = pd.concat([ds_vs, ds_css, ds_lss], ignore_index=True).set_index([\"region\", \"season\", \"comparison\"]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a77489cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similar performance to original performance for aunz 2018\n",
      "combonations tested:  [(3, 0.1), (5, 0.2), (3, 0.2), (5, 0.1)]\n",
      "\n",
      "similar performance to original performance for europe 2022-2023\n",
      "combonations tested:  [(5, 0.1), (5, 0.2)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_performance_results(performance_dict):\n",
    "    performance = []\n",
    "    if performance_dict[\"DS vs CSS\"] == performance_dict[\"DS vs VS\"]:\n",
    "        performance.append('reproducible selection performs the same as WHO vaccine strain')\n",
    "        \n",
    "        if performance_dict[\"DS vs LSS\"] < performance_dict['DS vs CSS']:\n",
    "            performance.append('added benefit from delayed selection')\n",
    "    \n",
    "    elif performance_dict[\"DS vs CSS\"] < performance_dict[\"DS vs VS\"]:\n",
    "        performance.append('reproducible selection performs beter than WHO vaccine strain')\n",
    "        \n",
    "        if performance_dict[\"DS vs LSS\"] < performance_dict['DS vs CSS']:\n",
    "            performance.append('added benefit from delayed selection')\n",
    "        \n",
    "\n",
    "    return \"; \".join(performance)\n",
    "    \n",
    "\n",
    "comps = [\"DS vs VS\", \"DS vs CSS\", \"DS vs LSS\"]\n",
    "for (region, season) in mismatch_df.index.unique():\n",
    "    gen = genetic_comparison.loc[(region, season)]\n",
    "    #care about epitope mutations \n",
    "    gen = gen[gen[\"epitope\"]==True]\n",
    "    #get counts \n",
    "    original_counts = gen.reset_index().groupby(\"comparison\")[\"H3 mutation\"].count().to_dict()\n",
    "    for comp in comps:\n",
    "        if comp not in original_counts.keys():\n",
    "            original_counts[comp] = 0\n",
    "    \n",
    "    df = mismatch_df.loc[(region, season)]\n",
    "    \n",
    "    for l in df[\"difference between identified dominant strain and original dominant strain (cs3, fdr0.2)\"].unique():\n",
    "        if not 'epitope' in l:\n",
    "            continue\n",
    "        \n",
    "        ep_muts = [i for i in l.split(\";\") if \"epitope\" in i][0].lstrip(\"epitope: \").split(\",\")\n",
    "        \n",
    "        updated_counts = original_counts.copy()\n",
    "      \n",
    "        for ep_mut in ep_muts:\n",
    "            h3_pos = int(ep_mut[1:-1])\n",
    "            \n",
    "            for comp in comps:\n",
    "                try:\n",
    "                    ml = gen.loc[comp][\"mature position\"].tolist()\n",
    "                    if h3_pos not in ml:\n",
    "                        updated_counts[comp] += 1\n",
    "                except:\n",
    "                    #comparison not in gen > count zero so new mutations is a count\n",
    "                    updated_counts[comp] += 1\n",
    "\n",
    "        original_performance = get_performance_results(original_counts)\n",
    "        updated_performance = get_performance_results(original_counts)\n",
    "        \n",
    "        if original_performance != updated_performance:\n",
    "            print (\"time to investigate\")\n",
    "            \n",
    "        else:\n",
    "            combos =df[df[\"difference between identified dominant strain and original dominant strain (cs3, fdr0.2)\"]==l].set_index([\"minimum cluster size\", \"fdr\"]).index.tolist() \n",
    "            print (f\"similar performance to original performance for {region} {season}\")\n",
    "            print (\"combonations tested: \", combos)\n",
    "            print ()\n",
    "        \n",
    "        \n",
    "        \n",
    "                \n",
    "                \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
